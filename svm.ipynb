{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in data using the functions that we made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneBatch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1BDwQ8VGLXKCv7GWSKGlCtfFs-kCokwGW\n",
      "From (redirected): https://drive.google.com/uc?id=1BDwQ8VGLXKCv7GWSKGlCtfFs-kCokwGW&confirm=t&uuid=cbd81fda-f00b-4c09-9cb9-365f3048abf5\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch2.zip\n",
      "100%|██████████| 667M/667M [00:47<00:00, 14.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1EAQiIiOsk1ZILaXN-cmbZ6xw1GsHdOtj\n",
      "From (redirected): https://drive.google.com/uc?id=1EAQiIiOsk1ZILaXN-cmbZ6xw1GsHdOtj&confirm=t&uuid=54b86da6-e5d6-4c36-8f96-e7048aa11727\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch3.zip\n",
      "100%|██████████| 631M/631M [00:45<00:00, 13.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1upmzQCmro-wRADEXpUKTk1kwudgkJqJi\n",
      "From (redirected): https://drive.google.com/uc?id=1upmzQCmro-wRADEXpUKTk1kwudgkJqJi&confirm=t&uuid=1965222a-7abc-4a28-8633-fe5cd73dfb43\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch4.zip\n",
      "100%|██████████| 714M/714M [00:51<00:00, 13.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1U4KKHJV3QqjG1Z8ZdKAnRD98m2rQRWBC\n",
      "From (redirected): https://drive.google.com/uc?id=1U4KKHJV3QqjG1Z8ZdKAnRD98m2rQRWBC&confirm=t&uuid=554ad02a-c871-48b0-aabc-fbc6ad781414\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch5.zip\n",
      "100%|██████████| 698M/698M [00:54<00:00, 12.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1w0ig4Z1SaQVi8RIZvYXTr7zsZwyVPJbz\n",
      "From (redirected): https://drive.google.com/uc?id=1w0ig4Z1SaQVi8RIZvYXTr7zsZwyVPJbz&confirm=t&uuid=cfa97a36-84e1-411a-af67-c7d4f8ed0218\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch6.zip\n",
      "100%|██████████| 813M/813M [00:59<00:00, 13.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1ublw71KXeRLMSuxNFxnmVA4z36v-PXN6\n",
      "From (redirected): https://drive.google.com/uc?id=1ublw71KXeRLMSuxNFxnmVA4z36v-PXN6&confirm=t&uuid=a624f9ee-53d8-4da8-8e09-3240a3c2b5bb\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch7.zip\n",
      "100%|██████████| 454M/454M [00:35<00:00, 12.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1ft0HPxsuIdRIxDqUY3akKHJABYnLpvP8\n",
      "From (redirected): https://drive.google.com/uc?id=1ft0HPxsuIdRIxDqUY3akKHJABYnLpvP8&confirm=t&uuid=c3127c38-155b-45d9-bf3b-a822138f9b3b\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch8.zip\n",
      "100%|██████████| 751M/751M [00:55<00:00, 13.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1qi-D3CkHcIXVIFslmlz6lVa2cQsMjFQA\n",
      "From (redirected): https://drive.google.com/uc?id=1qi-D3CkHcIXVIFslmlz6lVa2cQsMjFQA&confirm=t&uuid=136dc53f-7189-4f39-9f69-6a0b001496ec\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch9.zip\n",
      "100%|██████████| 1.41G/1.41G [01:40<00:00, 14.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1rbeMzL7AS0sCf8reVVyTPF6G_aPrMdFS\n",
      "From (redirected): https://drive.google.com/uc?id=1rbeMzL7AS0sCf8reVVyTPF6G_aPrMdFS&confirm=t&uuid=0f5eb141-e4b3-4e85-905d-b516a701a6cd\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch10.zip\n",
      "100%|██████████| 1.52G/1.52G [01:48<00:00, 14.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1-wA2Lw89Uii70ckW8tj10heDSaKnuQYS\n",
      "From (redirected): https://drive.google.com/uc?id=1-wA2Lw89Uii70ckW8tj10heDSaKnuQYS&confirm=t&uuid=4b22bc96-9741-4a9b-befa-363bc4fcb6f7\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch11.zip\n",
      "100%|██████████| 560M/560M [00:38<00:00, 14.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1vRNwzXx-ZvMKHQXYMGLt4zkbDmt85Jm4\n",
      "From (redirected): https://drive.google.com/uc?id=1vRNwzXx-ZvMKHQXYMGLt4zkbDmt85Jm4&confirm=t&uuid=06d90562-f503-4efb-b5b6-648d445c977b\n",
      "To: /Users/sergiomartelo/Documents/college/ML/project/BJJ_machine_learning/batch12.zip\n",
      "100%|██████████| 630M/630M [00:43<00:00, 14.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Run if you want one batch\n",
    "import data_loading as dt\n",
    "import os\n",
    "\n",
    "\n",
    "if oneBatch:\n",
    "    batchNum = 1\n",
    "    if os.path.exists(f'batch{batchNum}/part_{batchNum}/'):\n",
    "        ids, images = dt.importImages(f'batch{batchNum}/part_{batchNum}/')\n",
    "    else:\n",
    "        ids, images = dt.loadImageBatch(batchNum)\n",
    "else:\n",
    "    batchNums = list(range(1,13))\n",
    "    ids, images = dt.loadImageBatches(batchNums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting annotations and getting them into the correct order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>standing</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>standing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>standing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   position  image\n",
       "0  standing      1\n",
       "1  standing      2\n",
       "2  standing      3\n",
       "3  standing      4\n",
       "4  standing      5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "annotations = pd.read_csv(\"data/annotations.csv\")\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_maps= {\"standing\": 0, \n",
    "                \"takedown1\": 1,\n",
    "                \"takedown2\": 2,\n",
    "                \"open_guard1\": 3,\n",
    "                \"open_guard2\": 4,\n",
    "                \"half_guard1\": 5,\n",
    "                \"half_guard2\": 6,\n",
    "                \"closed_guard1\": 7,\n",
    "                \"closed_guard2\": 8,\n",
    "                \"5050_guard\": 9,\n",
    "                \"mount1\": 10,\n",
    "                \"mount2\": 11,\n",
    "                \"back1\": 12,\n",
    "                \"back2\": 13,\n",
    "                \"turtle1\": 14,\n",
    "                \"turtle2\": 15,               \n",
    "                \"side_control1\" : 16,\n",
    "                \"side_control2\" : 17}\n",
    "\n",
    "\n",
    "labels = []\n",
    "for id in ids:\n",
    "    labels.append(position_maps[annotations[annotations['image'] == id]['position'].reset_index(drop=True)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting images to tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Converting into torch tensors\n",
    "for i, img in enumerate(images):\n",
    "    images[i] = torch.from_numpy(np.array(img))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120279, 64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9060192883272364\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images.reshape((len(images),-1)), labels, test_size=0.25, random_state=10)\n",
    "\n",
    "# Create a pipeline that scales the data and trains an SVM using SGD\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3)\n",
    ")\n",
    "\n",
    "# Train the SVM using the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report and confusion matrix\n",
    "print(f\"Accuracy: {clf.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('sgdclassifier', SGDClassifier())]):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      4147\n",
      "           1       0.83      0.68      0.75       647\n",
      "           2       0.77      0.70      0.73       669\n",
      "           3       0.91      0.89      0.90      1894\n",
      "           4       0.90      0.83      0.86      1800\n",
      "           5       0.90      0.90      0.90      1194\n",
      "           6       0.91      0.93      0.92      1509\n",
      "           7       0.91      0.93      0.92      1525\n",
      "           8       0.85      0.76      0.80      1399\n",
      "           9       0.89      0.96      0.93      2128\n",
      "          10       0.90      0.88      0.89      1454\n",
      "          11       0.92      0.91      0.91      1480\n",
      "          12       0.95      0.93      0.94      1788\n",
      "          13       0.94      0.97      0.96      1523\n",
      "          14       0.95      0.98      0.97      2188\n",
      "          15       0.96      0.98      0.97      1907\n",
      "          16       0.82      0.86      0.84      1521\n",
      "          17       0.86      0.81      0.84      1297\n",
      "\n",
      "    accuracy                           0.91     30070\n",
      "   macro avg       0.89      0.88      0.89     30070\n",
      "weighted avg       0.91      0.91      0.90     30070\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[4033   46   34    4    8    0    0    0    0    0    0    0    9    6\n",
      "     1    6    0    0]\n",
      " [ 103  443   52    1    9    0    0    1    0    0    0    0   11   14\n",
      "     7    6    0    0]\n",
      " [ 124   29  467    8    6    0    0    0    0    0    0    0    9    6\n",
      "    11    8    0    1]\n",
      " [  32    1    1 1681   35    7    9   19   38   16    1    3    5    1\n",
      "     1   22    7   15]\n",
      " [  51    5   19   46 1488    2   27   12   23   34   20   11    0    9\n",
      "     7    1   40    5]\n",
      " [   0    0    0    1    3 1077   13    7   14   15    4    0    0    0\n",
      "     0    0   30   30]\n",
      " [   0    0    0    9   11    5 1403    1   27   24    1    0    0    0\n",
      "     0    0   26    2]\n",
      " [   0    0    0   12   17    4    5 1423    2   15    5    9    0    0\n",
      "     2    4   24    3]\n",
      " [  18    0    0   38   40   42   32   23 1065   55    5   14    0    0\n",
      "     0    0   41   26]\n",
      " [   0    0    0    0    4    2   16   17   18 2044    2    7    1    4\n",
      "     0    0    6    7]\n",
      " [   0    0    0    4    9    0    3   14   12   27 1273   39    0    0\n",
      "     0    0   45   28]\n",
      " [   0    0    0    1   15    2    1   16    3   16   30 1347    0    2\n",
      "     2    5   18   22]\n",
      " [  31    3   17    0    3    0    0    0    0    0    0    0 1655   27\n",
      "    33    3    0   16]\n",
      " [   4    8    4    0    0    0    0    0    0    0    0    0   14 1471\n",
      "    11    9    0    2]\n",
      " [   0    0   11    0    0    0    0    0    0    0    0    0   14    4\n",
      "  2146   13    0    0]\n",
      " [   0    0    3    0    0    0    0    0    0    0    0    0    6    7\n",
      "    24 1867    0    0]\n",
      " [   0    0    0   20    4   16   18   18   37   24   47   17    0    0\n",
      "     0    0 1304   16]\n",
      " [   7    0    1   19    1   34   13   11   17   19   26   22   12    6\n",
      "     7    3   42 1057]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(y_test, y_pred)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
